{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133755bf-3d74-46b0-bac5-e099e974752a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Scripts.essentials import *\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "p = \"Data/\"\n",
    "train_x = np.load(p + \"train_x_MANUAL.npy\")\n",
    "test_x = np.load(p + \"test_x_MANUAL.npy\")\n",
    "val_x = np.load(p + \"val_x_MANUAL.npy\")\n",
    "\n",
    "train_y = np.load(p + \"train_y_46.npy\")\n",
    "test_y = np.load(p + \"test_y_46.npy\")\n",
    "val_y = np.load(p + \"val_y_46.npy\")\n",
    "\n",
    "train_lgm = np.load(p + \"train_lgm.npy\")\n",
    "test_lgm = np.load(p + \"test_lgm.npy\")\n",
    "val_lgm = np.load(p + \"val_lgm.npy\")\n",
    "\n",
    "# Binary encoding from lgm to mutant vs. wildtype\n",
    "train_lgm = np.argmax(train_lgm, axis = 1)\n",
    "test_lgm = np.argmax(test_lgm, axis = 1)\n",
    "val_lgm = np.argmax(val_lgm, axis = 1)\n",
    "\n",
    "train_lgm = np.where(train_lgm > 2, 0, 1)\n",
    "test_lgm = np.where(test_lgm > 2, 0, 1)\n",
    "val_lgm = np.where(val_lgm > 2, 0, 1)\n",
    "\n",
    "eye = np.eye(2)\n",
    "\n",
    "train_lgm = eye[train_lgm]\n",
    "val_lgm = eye[val_lgm]\n",
    "test_lgm = eye[test_lgm]\n",
    "\n",
    "# Class weights for the sample ids\n",
    "counts = np.bincount(np.argmax(train_y, axis = 1))\n",
    "class_weights = np.sqrt((1/(counts/np.max(counts))))\n",
    "\n",
    "cw_id = {}\n",
    "\n",
    "for i in range(len(class_weights)):\n",
    "    cw_id[i] = class_weights[i]\n",
    "    print(i,\":\", cw_id[i], \"(\", counts[i], \" spectra in training set)\")\n",
    "\n",
    "# Class weights for the lgm classes\n",
    "counts = np.bincount(np.argmax(train_lgm, axis = 1))\n",
    "class_weights = np.sqrt((1/(counts/np.max(counts))))\n",
    "\n",
    "cw_lgm = {}\n",
    "\n",
    "for i in range(len(class_weights)):\n",
    "    cw_lgm[i] = class_weights[i]\n",
    "    print(i,\":\", cw_lgm[i], \"(\", counts[i], \" spectra in training set)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26bcaa2-7406-43e5-b5f3-7e251dbb5e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "accuracies = []\n",
    "for i in range(1738):\n",
    "    d = train_x[:, i]\n",
    "\n",
    "    if np.sum(d) == 0:\n",
    "        accuracies.append(0)\n",
    "        continue # Do not learn 0-features\n",
    "\n",
    "    # Normalize the features and save the min and max to preprocess val and test data\n",
    "    min_ = np.min(d)\n",
    "    max_ = np.max(d)\n",
    "    d = (d - min_)/(max_ - min_)\n",
    "    \n",
    "    model = DecisionTreeClassifier(random_state=0, class_weight=cw_id)\n",
    "    model.fit(d.reshape((-1, 1)), np.argmax(train_y, axis = 1))\n",
    "\n",
    "    # Evaluate on the test data\n",
    "    preds = model.predict(((test_x[:, i] - min_) / (max_ - min_)).reshape((-1, 1)))\n",
    "    \n",
    "\n",
    "    acc = balanced_accuracy_score(np.argmax(test_y, axis = 1), preds)\n",
    "    print(i, \":\", acc)\n",
    "    accuracies.append(acc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b391808-7689-4124-b6bd-85d7783a06e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(accuracies)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfca3c6-ab36-4d89-954d-cbdb8f4cbd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can we use one feature to predict the lgm calsses?\n",
    "\n",
    "accuracies_lgm = []\n",
    "for i in range(1738):\n",
    "    d = train_x[:, i]\n",
    "\n",
    "    if np.sum(d) == 0:\n",
    "        accuracies_lgm.append(0)\n",
    "        continue # Do not learn 0-features\n",
    "\n",
    "    # Normalize the features and save the min and max to preprocess val and test data\n",
    "    min_ = np.min(d)\n",
    "    max_ = np.max(d)\n",
    "    d = (d - min_)/(max_ - min_)\n",
    "\n",
    "    model = DecisionTreeClassifier(random_state=0, class_weight=cw_lgm)\n",
    "    model.fit(d.reshape((-1, 1)), np.argmax(train_lgm, axis = 1))\n",
    "\n",
    "    # Evaluate on the test data\n",
    "    preds = model.predict(((test_x[:, i] - min_) / (max_ - min_)).reshape((-1, 1)))\n",
    "\n",
    "    acc = balanced_accuracy_score(np.argmax(test_lgm, axis = 1), preds)\n",
    "    print(i, \":\", acc)\n",
    "    accuracies_lgm.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bc0e7b-eae0-431a-8123-373f96e322f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(accuracies_lgm)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe14a5b-a752-44b4-bc7c-fcd15af7c1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"Results/(MANUAL)SingleFeatureMetrics/single_id.npy\", accuracies)\n",
    "np.save(\"Results/(MANUAL)SingleFeatureMetrics/single_lgm.npy\", accuracies_lgm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59882df-8479-437d-88cd-4c7a37bdc193",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "p = \"Data/\"\n",
    "train_x = np.load(p + \"train_x_MANUAL.npy\")\n",
    "accuracies_id = np.load(\"Results/(MANUAL)SingleFeatureMetrics/single_id.npy\")\n",
    "accuracies_lgm = np.load(\"Results/(MANUAL)SingleFeatureMetrics/single_lgm.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161319c0-6828-42d7-adef-8373c7b38243",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 30})\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "\n",
    "plt.figure(figsize = (15, 5))\n",
    "train_x = np.load(p + \"train_x_MANUAL.npy\")\n",
    "accuracies_id = np.load(\"Results/(MANUAL)SingleFeatureMetrics/single_id.npy\")\n",
    "accuracies_lgm = np.load(\"Results/(MANUAL)SingleFeatureMetrics/single_lgm.npy\")\n",
    "mean = np.mean(train_x, axis = 0)\n",
    "\n",
    "x = np.arange(len(train_x[0]))\n",
    "x = x[mean != 0.0]\n",
    "accuracies_id = accuracies_id[mean != 0.0]\n",
    "accuracies_lgm = accuracies_lgm[mean != 0.0]\n",
    "mean = mean[mean != 0.0]\n",
    "\n",
    "plt.plot(mean, color = \"black\", linestyle = \"--\")\n",
    "\n",
    "plt.fill_between(np.arange(len(x)), np.where(accuracies_id > 1/46 + 0.02, mean, 0), 0, color = \"red\", alpha = 0.5)\n",
    "plt.fill_between(np.arange(len(x)), np.where(accuracies_lgm > 1/2 + 0.1, mean, 0), 0, color = \"green\", alpha = 0.5)\n",
    "\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xticks([])\n",
    "plt.savefig(\"Images/(MANUAL)OneFeatureLearning.png\", format=\"png\", transparent = True,\n",
    "                    dpi = 300,\n",
    "                    bbox_inches='tight',\n",
    "                    pad_inches=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a821f345-f4e8-4628-b243-ed6f75176204",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
