{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6d175d-55f4-432f-8715-4d59e942251c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Scripts.essentials import *\n",
    "from sklearn.metrics import PrecisionRecallDisplay, auc\n",
    "    \n",
    "enc = make_encoder()\n",
    "enc.load_weights(\"Models/data_encoders/(MANUAL)MutantVsWildtype_importance.h5\")\n",
    "\n",
    "batch_size = 256\n",
    "epochs = 300\n",
    "lr = 0.00005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ca77a5-6ede-4f24-b871-01460029746f",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = \"Data/\"\n",
    "#limit = 10000\n",
    "train_x = enc.predict(np.load(p + \"train_x_MANUAL.npy\"), batch_size = 128)\n",
    "test_x = enc.predict(np.load(p + \"test_x_MANUAL.npy\"), batch_size = 128)\n",
    "val_x = enc.predict(np.load(p + \"val_x_MANUAL.npy\"), batch_size = 128)\n",
    "\n",
    "train_y = np.load(p + \"train_y_46.npy\")\n",
    "test_y = np.load(p + \"test_y_46.npy\")\n",
    "val_y = np.load(p + \"val_y_46.npy\")\n",
    "\n",
    "train_lgm = np.load(p + \"train_lgm.npy\")\n",
    "test_lgm = np.load(p + \"test_lgm.npy\")\n",
    "val_lgm = np.load(p + \"val_lgm.npy\")\n",
    "\n",
    "np.random.seed(0)\n",
    "ix = np.arange(len(train_x))\n",
    "np.random.shuffle(ix)\n",
    "train_x = train_x[ix]\n",
    "train_y = train_y[ix]\n",
    "train_lgm = train_lgm[ix]\n",
    "\n",
    "ix = np.arange(len(val_x))\n",
    "np.random.shuffle(ix)\n",
    "val_x = val_x[ix]\n",
    "val_y = val_y[ix]\n",
    "val_lgm = val_lgm[ix]\n",
    "\n",
    "train_lgm = np.argmax(train_lgm, axis = 1)\n",
    "test_lgm = np.argmax(test_lgm, axis = 1)\n",
    "val_lgm = np.argmax(val_lgm, axis = 1)\n",
    "train_lgm = np.where(train_lgm > 2, 0, 1)\n",
    "test_lgm = np.where(test_lgm > 2, 0, 1)\n",
    "val_lgm = np.where(val_lgm > 2, 0, 1)\n",
    "\n",
    "eye = np.eye(2)\n",
    "\n",
    "train_lgm = eye[train_lgm]\n",
    "test_lgm = eye[test_lgm]\n",
    "val_lgm = eye[val_lgm]\n",
    "print(train_lgm)\n",
    "\n",
    "plt.plot(train_x[:100].T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0f1347-60fa-4343-83a1-7d86c63bf8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0,\n",
    "    patience = 4,\n",
    "    verbose=0,\n",
    "    mode=\"auto\",\n",
    "    baseline=None,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "\n",
    "import pickle\n",
    "plt.rcParams.update({'font.size': 40})\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "reset_seed()\n",
    "sample_model = make_split_model(lr = lr, inp_size = len(train_x[0]), out_dims = [len(train_y[0]), len(train_lgm[0])])\n",
    "sample_model.summary()\n",
    "\n",
    "hist = sample_model.fit(train_x, [train_y, train_lgm],\n",
    "                          epochs = epochs,\n",
    "                          batch_size = batch_size,\n",
    "                          validation_data = (val_x, [val_y, val_lgm]),\n",
    "                          callbacks = [early_stop]\n",
    "                       )\n",
    "\n",
    "sample_model.save_weights(\"Models/MANUAL_Bias_quantifier_after.h5\")\n",
    "\n",
    "sample_model.load_weights(\"Models/MANUAL_Bias_quantifier_after.h5\")\n",
    "\n",
    "# convert the history.history dict to a pandas DataFrame:     \n",
    "hist_df = pd.DataFrame(hist.history) \n",
    "\n",
    "# or save to csv: \n",
    "hist_csv_file = 'history_with_encoder.csv'\n",
    "with open(hist_csv_file, mode='w') as f:\n",
    "    hist_df.to_csv(f)\n",
    "    \n",
    "y_p = sample_model.predict(test_x, batch_size = 128)\n",
    "y_p_id = np.argmax(y_p[0], axis = 1)\n",
    "y_p_lgm = np.argmax(y_p[1], axis = 1)\n",
    "\n",
    "# For the id labels\n",
    "y_t = np.argmax(test_y, axis = 1)\n",
    "test_acc = balanced_accuracy_score(y_t, y_p_id)\n",
    "print(test_acc)\n",
    "gc.collect()\n",
    "\n",
    "id_accuracies = []\n",
    "lgm_accuracies = []\n",
    "displays_id = []\n",
    "aupr_metrics_id = []\n",
    "for n in np.unique(y_t):\n",
    "\n",
    "    # Base the AUPR on one vs. all\n",
    "    temp_yt = np.where(y_t == n, 1, 0)\n",
    "    temp_yp = np.where(y_p_id == n, 1, 0)\n",
    "    disp = PrecisionRecallDisplay.from_predictions(temp_yt, temp_yp)\n",
    "    displays_id.append(disp)\n",
    "    aupr_metrics_id.append(auc(disp.recall, disp.precision))\n",
    "\n",
    "    # Get the accuracy on individual samples\n",
    "    sample_pred = y_p_id[y_t == n]\n",
    "    acc = np.sum(np.where(sample_pred == n, 1, 0))/len(sample_pred)\n",
    "    id_accuracies.append(np.round(acc, 2))\n",
    "\n",
    "    # Get the accuracy on individual samples\n",
    "    sample_true_lgm = np.argmax(test_lgm, axis = 1)\n",
    "    sample_true_lgm = sample_true_lgm[y_t == n]\n",
    "    sample_pred = y_p_lgm[y_t == n]\n",
    "    acc = np.sum(np.where(sample_pred == sample_true_lgm, 1, 0))/len(sample_pred)\n",
    "    lgm_accuracies.append(np.round(acc, 2))\n",
    "\n",
    "np.save(\"Results/(MANUAL)FinalIDAccuracies.npy\", id_accuracies)\n",
    "np.save(\"Results/(MANUAL)FinalLGMAccuracies.npy\", lgm_accuracies)\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize = (10, 10))\n",
    "for n, disp in enumerate(displays_id):\n",
    "    disp.plot(ax, name = n+1)\n",
    "    \n",
    "ax.legend(loc='center left', bbox_to_anchor=(1.04, 0.5),\n",
    "          ncol=3, fancybox=True, shadow=True)\n",
    "\n",
    "plt.savefig(\"Images/Features/(MANUAL)EcoderEval_ID_After.png\", format=\"png\", transparent = True,\n",
    "                    dpi = 300,\n",
    "                    bbox_inches='tight',\n",
    "                    pad_inches=0.5)\n",
    "plt.show()\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "# For the lgm labels\n",
    "y_t = np.argmax(test_lgm, axis = 1)\n",
    "test_acc = balanced_accuracy_score(y_t, y_p_lgm)\n",
    "print(test_acc)\n",
    "gc.collect()\n",
    "\n",
    "displays_lgm = []\n",
    "aupr_metrics_lgm = []\n",
    "for n in np.unique(y_t):\n",
    "    temp_yt = np.where(y_t == n, 1, 0)\n",
    "    temp_yp = np.where(y_p_lgm == n, 1, 0)\n",
    "    disp = PrecisionRecallDisplay.from_predictions(temp_yt, temp_yp)\n",
    "    displays_lgm.append(disp)\n",
    "\n",
    "    aupr_metrics_lgm.append(auc(disp.recall, disp.precision))\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize = (10, 10))\n",
    "for n, disp in enumerate(displays_lgm):\n",
    "    disp.plot(ax, name = n+1)\n",
    "\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1.04, 1),\n",
    "          ncol=3, fancybox=True, shadow=True)\n",
    "\n",
    "plt.savefig(\"Images/Features/(MANUAL)EcoderEval_LGM_After.png\", format=\"png\", transparent = True,\n",
    "                    dpi = 300,\n",
    "                    bbox_inches='tight',\n",
    "                    pad_inches=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa52339-4395-48fe-a7f0-500add31f62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"Results/avgpr_id_after.npy\", avgpr)\n",
    "np.save(\"Results/aupr_id_after.npy\", aupr_metrics_id)\n",
    "np.save(\"Results/aupr_lgm_after.npy\", aupr_metrics_lgm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9bcc11-ca73-4bdd-87b2-5f8887da59eb",
   "metadata": {},
   "source": [
    "# Performance without encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0377c1d-29d9-48d7-a7c9-dbd3d270bb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "# Load the data without encoder transformation\n",
    "p = \"Data/\"\n",
    "train_x = np.load(p + \"train_x_MANUAL.npy\")\n",
    "test_x = np.load(p + \"test_x_MANUAL.npy\")\n",
    "val_x = np.load(p + \"val_x_MANUAL.npy\")\n",
    "\n",
    "train_y = np.load(p + \"train_y_46.npy\")\n",
    "test_y = np.load(p + \"test_y_46.npy\")\n",
    "val_y = np.load(p + \"val_y_46.npy\")\n",
    "\n",
    "train_lgm = np.load(p + \"train_lgm.npy\")\n",
    "test_lgm = np.load(p + \"test_lgm.npy\")\n",
    "val_lgm = np.load(p + \"val_lgm.npy\")\n",
    "\n",
    "np.random.seed(0)\n",
    "ix = np.arange(len(train_x))\n",
    "np.random.shuffle(ix)\n",
    "train_x = train_x[ix]\n",
    "train_y = train_y[ix]\n",
    "train_lgm = train_lgm[ix]\n",
    "\n",
    "ix = np.arange(len(val_x))\n",
    "np.random.shuffle(ix)\n",
    "val_x = val_x[ix]\n",
    "val_y = val_y[ix]\n",
    "val_lgm = val_lgm[ix]\n",
    "\n",
    "train_lgm = np.argmax(train_lgm, axis = 1)\n",
    "test_lgm = np.argmax(test_lgm, axis = 1)\n",
    "val_lgm = np.argmax(val_lgm, axis = 1)\n",
    "train_lgm = np.where(train_lgm > 2, 0, 1)\n",
    "test_lgm = np.where(test_lgm > 2, 0, 1)\n",
    "val_lgm = np.where(val_lgm > 2, 0, 1)\n",
    "\n",
    "eye = np.eye(2)\n",
    "\n",
    "train_lgm = eye[train_lgm]\n",
    "test_lgm = eye[test_lgm]\n",
    "val_lgm = eye[val_lgm]\n",
    "print(train_lgm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a469db1-819c-40d1-9d97-1663d7ec7d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 40})\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "reset_seed()\n",
    "sample_model = make_split_model(lr = lr, inp_size = len(train_x[0]), out_dims = [len(train_y[0]), len(train_lgm[0])])\n",
    "sample_model.summary()\n",
    "\n",
    "sample_model.load_weights(\"Models\\MANUAL_Bias_quantifier.h5\")\n",
    "\n",
    "y_p = sample_model.predict(test_x, batch_size = 128)\n",
    "y_p_id = np.argmax(y_p[0], axis = 1)\n",
    "y_p_lgm = np.argmax(y_p[1], axis = 1)\n",
    "\n",
    "# For the id labels\n",
    "y_t = np.argmax(test_y, axis = 1)\n",
    "test_acc = balanced_accuracy_score(y_t, y_p_id)\n",
    "print(test_acc)\n",
    "gc.collect()\n",
    "\n",
    "id_accuracies = []\n",
    "lgm_accuracies = []\n",
    "\n",
    "displays_id = []\n",
    "aupr_metrics_id = []\n",
    "for n in np.unique(y_t):\n",
    "\n",
    "    # Base the AUPR on one vs. all\n",
    "    temp_yt = np.where(y_t == n, 1, 0)\n",
    "    temp_yp = np.where(y_p_id == n, 1, 0)\n",
    "    disp = PrecisionRecallDisplay.from_predictions(temp_yt, temp_yp)\n",
    "    displays_id.append(disp)\n",
    "    aupr_metrics_id.append(auc(disp.recall, disp.precision))\n",
    "\n",
    "    # Get the accuracy on individual samples\n",
    "    sample_pred = y_p_id[y_t == n]\n",
    "    acc = np.sum(np.where(sample_pred == n, 1, 0))/len(sample_pred)\n",
    "    id_accuracies.append(np.round(acc, 2))\n",
    "\n",
    "    # Get the accuracy on individual samples\n",
    "    sample_true_lgm = np.argmax(test_lgm, axis = 1)\n",
    "    sample_true_lgm = sample_true_lgm[y_t == n]\n",
    "    sample_pred = y_p_lgm[y_t == n]\n",
    "    acc = np.sum(np.where(sample_pred == sample_true_lgm, 1, 0))/len(sample_pred)\n",
    "    lgm_accuracies.append(np.round(acc, 2))\n",
    "\n",
    "np.save(\"Results/(MANUAL)FinalIDAccuracies(Before).npy\", id_accuracies)\n",
    "np.save(\"Results/(MANUAL)FinalLGMAccuracies(Before).npy\", lgm_accuracies)\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize = (10, 10))\n",
    "for n, disp in enumerate(displays_id):\n",
    "    disp.plot(ax, name = n+1)\n",
    "    \n",
    "ax.legend(loc='center left', bbox_to_anchor=(1.04, 0.5),\n",
    "          ncol=3, fancybox=True, shadow=True)\n",
    "\n",
    "plt.savefig(\"Images/Features/(MANUAL)EcoderEval_ID_Before.png\", format=\"png\", transparent = True,\n",
    "                    dpi = 300,\n",
    "                    bbox_inches='tight',\n",
    "                    pad_inches=0.5)\n",
    "plt.show()\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "# For the lgm labels\n",
    "y_t = np.argmax(test_lgm, axis = 1)\n",
    "test_acc = balanced_accuracy_score(y_t, y_p_lgm)\n",
    "print(test_acc)\n",
    "gc.collect()\n",
    "\n",
    "displays_lgm = []\n",
    "aupr_metrics_lgm = []\n",
    "for n in np.unique(y_t):\n",
    "    temp_yt = np.where(y_t == n, 1, 0)\n",
    "    temp_yp = np.where(y_p_lgm == n, 1, 0)\n",
    "    disp = PrecisionRecallDisplay.from_predictions(temp_yt, temp_yp)\n",
    "    displays_lgm.append(disp)\n",
    "\n",
    "    aupr_metrics_lgm.append(auc(disp.recall, disp.precision))\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize = (10, 10))\n",
    "for n, disp in enumerate(displays_lgm):\n",
    "    disp.plot(ax, name = n+1)\n",
    "\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1.04, 1),\n",
    "          ncol=1, fancybox=True, shadow=True)\n",
    "\n",
    "plt.savefig(\"Images/Features/(MANUAL)EcoderEval_LGM_Before.png\", format=\"png\", transparent = True,\n",
    "                    dpi = 300,\n",
    "                    bbox_inches='tight',\n",
    "                    pad_inches=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fd3cfa-fcf0-4c4a-9cd6-a841a26bba77",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 40})\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "\n",
    "avgpr = [d.average_precision for d in displays_id]\n",
    "plt.boxplot([aupr_metrics_id, avgpr])\n",
    "plt.ylim([0, 1])\n",
    "plt.savefig(\"Images/Features/(MANUAL)EcoderEval_IDperLGM_Before_boxplot.png\", format=\"png\", transparent = True,\n",
    "                    dpi = 300,\n",
    "                    bbox_inches='tight',\n",
    "                    pad_inches=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7778dd37-0646-4d4e-abf0-42fd6acd1535",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"Results/avgpr_id.npy\", avgpr)\n",
    "np.save(\"Results/aupr_id.npy\", aupr_metrics_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f958566f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "# Load the data without encoder transformation\n",
    "p = \"Data/\"\n",
    "train_x = np.load(p + \"train_x.npy\")\n",
    "test_x = np.load(p + \"test_x.npy\")\n",
    "val_x = np.load(p + \"val_x.npy\")\n",
    "\n",
    "train_y = np.load(p + \"train_y_46.npy\")\n",
    "test_y = np.load(p + \"test_y_46.npy\")\n",
    "val_y = np.load(p + \"val_y_46.npy\")\n",
    "\n",
    "train_lgm = np.load(p + \"train_lgm.npy\")\n",
    "test_lgm = np.load(p + \"test_lgm.npy\")\n",
    "val_lgm = np.load(p + \"val_lgm.npy\")\n",
    "\n",
    "np.random.seed(0)\n",
    "ix = np.arange(len(train_x))\n",
    "np.random.shuffle(ix)\n",
    "train_x = train_x[ix]\n",
    "train_y = train_y[ix]\n",
    "train_lgm = train_lgm[ix]\n",
    "\n",
    "ix = np.arange(len(val_x))\n",
    "np.random.shuffle(ix)\n",
    "val_x = val_x[ix]\n",
    "val_y = val_y[ix]\n",
    "val_lgm = val_lgm[ix]\n",
    "\n",
    "train_lgm = np.argmax(train_lgm, axis = 1)\n",
    "test_lgm = np.argmax(test_lgm, axis = 1)\n",
    "val_lgm = np.argmax(val_lgm, axis = 1)\n",
    "train_lgm = np.where(train_lgm > 2, 0, 1)\n",
    "test_lgm = np.where(test_lgm > 2, 0, 1)\n",
    "val_lgm = np.where(val_lgm > 2, 0, 1)\n",
    "\n",
    "eye = np.eye(2)\n",
    "\n",
    "train_lgm = eye[train_lgm]\n",
    "test_lgm = eye[test_lgm]\n",
    "val_lgm = eye[val_lgm]\n",
    "print(train_lgm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51794233",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 40})\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "reset_seed()\n",
    "sample_model = make_split_model(lr = lr, inp_size = len(train_x[0]), out_dims = [len(train_y[0]), len(train_lgm[0])])\n",
    "sample_model.summary()\n",
    "\n",
    "sample_model.load_weights(\"Models\\RAW_Bias_quantifier.h5\")\n",
    "\n",
    "y_p = sample_model.predict(test_x, batch_size = 128)\n",
    "y_p_id = np.argmax(y_p[0], axis = 1)\n",
    "y_p_lgm = np.argmax(y_p[1], axis = 1)\n",
    "\n",
    "# For the id labels\n",
    "y_t = np.argmax(test_y, axis = 1)\n",
    "test_acc = balanced_accuracy_score(y_t, y_p_id)\n",
    "print(test_acc)\n",
    "gc.collect()\n",
    "\n",
    "id_accuracies = []\n",
    "lgm_accuracies = []\n",
    "\n",
    "displays_id = []\n",
    "aupr_metrics_id = []\n",
    "for n in np.unique(y_t):\n",
    "\n",
    "    # Base the AUPR on one vs. all\n",
    "    temp_yt = np.where(y_t == n, 1, 0)\n",
    "    temp_yp = np.where(y_p_id == n, 1, 0)\n",
    "    disp = PrecisionRecallDisplay.from_predictions(temp_yt, temp_yp)\n",
    "    displays_id.append(disp)\n",
    "    aupr_metrics_id.append(auc(disp.recall, disp.precision))\n",
    "\n",
    "    # Get the accuracy on individual samples\n",
    "    sample_pred = y_p_id[y_t == n]\n",
    "    acc = np.sum(np.where(sample_pred == n, 1, 0))/len(sample_pred)\n",
    "    id_accuracies.append(np.round(acc, 2))\n",
    "\n",
    "    # Get the accuracy on individual samples\n",
    "    sample_true_lgm = np.argmax(test_lgm, axis = 1)\n",
    "    sample_true_lgm = sample_true_lgm[y_t == n]\n",
    "    sample_pred = y_p_lgm[y_t == n]\n",
    "    acc = np.sum(np.where(sample_pred == sample_true_lgm, 1, 0))/len(sample_pred)\n",
    "    lgm_accuracies.append(np.round(acc, 2))\n",
    "\n",
    "np.save(\"Results/(RAW)FinalIDAccuracies(Before).npy\", id_accuracies)\n",
    "np.save(\"Results/(RAW)FinalLGMAccuracies(Before).npy\", lgm_accuracies)\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize = (10, 10))\n",
    "for n, disp in enumerate(displays_id):\n",
    "    disp.plot(ax, name = n+1)\n",
    "    \n",
    "ax.legend(loc='center left', bbox_to_anchor=(1.04, 0.5),\n",
    "          ncol=3, fancybox=True, shadow=True)\n",
    "\n",
    "plt.savefig(\"Images/Features/(RAW)EcoderEval_ID_Before.png\", format=\"png\", transparent = True,\n",
    "                    dpi = 300,\n",
    "                    bbox_inches='tight',\n",
    "                    pad_inches=0.5)\n",
    "plt.show()\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "# For the lgm labels\n",
    "y_t = np.argmax(test_lgm, axis = 1)\n",
    "test_acc = balanced_accuracy_score(y_t, y_p_lgm)\n",
    "print(test_acc)\n",
    "gc.collect()\n",
    "\n",
    "displays_lgm = []\n",
    "aupr_metrics_lgm = []\n",
    "for n in np.unique(y_t):\n",
    "    temp_yt = np.where(y_t == n, 1, 0)\n",
    "    temp_yp = np.where(y_p_lgm == n, 1, 0)\n",
    "    disp = PrecisionRecallDisplay.from_predictions(temp_yt, temp_yp)\n",
    "    displays_lgm.append(disp)\n",
    "\n",
    "    aupr_metrics_lgm.append(auc(disp.recall, disp.precision))\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize = (10, 10))\n",
    "for n, disp in enumerate(displays_lgm):\n",
    "    disp.plot(ax, name = n+1)\n",
    "\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1.04, 1),\n",
    "          ncol=1, fancybox=True, shadow=True)\n",
    "\n",
    "plt.savefig(\"Images/Features/(RAW)EcoderEval_LGM_Before.png\", format=\"png\", transparent = True,\n",
    "                    dpi = 300,\n",
    "                    bbox_inches='tight',\n",
    "                    pad_inches=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb12b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"Results/aupr_id_RAW.npy\", aupr_metrics_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597844e0-06d4-41bf-b144-46d8c50f8c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "before = np.load(\"Results/(MANUAL)FinalIDAccuracies(Before).npy\")\n",
    "after = np.load(\"Results/(MANUAL)FinalIDAccuracies.npy\")\n",
    "raw_test_acc = np.load(\"Results/(RAW)FinalIDAccuracies(Before).npy\")\n",
    "plt.rcParams.update({'font.size': 30})\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "\n",
    "sorting = np.argsort(after)\n",
    "\n",
    "plt.figure(figsize = (10, 5))\n",
    "\n",
    "plt.scatter(np.arange(len(before)), np.array(raw_test_acc)[sorting], label = \"Raw data (\" + str(np.round(np.mean(raw_test_acc), 2)) + \")\")\n",
    "plt.scatter(np.arange(len(before)), np.array(before)[sorting], label = \"Before (\" + str(np.round(np.mean(before), 2)) + \")\")\n",
    "plt.scatter(np.arange(len(before)), np.array(after)[sorting], label = \"After (\" + str(np.round(np.mean(after), 2)) + \")\")\n",
    "plt.ylim([-0.1, 1.1])\n",
    "plt.legend(fontsize = 20)\n",
    "\n",
    "plt.savefig(\"Images/Histories/(MANUAL)SpectrumEffectImprovement_accuracy.png\", format=\"png\", transparent = True,\n",
    "                    dpi = 1000,\n",
    "                    bbox_inches='tight',\n",
    "                    pad_inches=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a5990d-8c78-42dc-aebe-34acc27e40af",
   "metadata": {},
   "outputs": [],
   "source": [
    "before = np.load(\"Results/aupr_id.npy\")\n",
    "after = np.load(\"Results/aupr_id_after.npy\")\n",
    "raw_test_auc = np.load(\"Results/aupr_id_RAW.npy\")\n",
    "\n",
    "plt.rcParams.update({'font.size': 30})\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "\n",
    "sorting = np.argsort(after)\n",
    "\n",
    "plt.figure(figsize = (10, 5))\n",
    "plt.scatter(np.arange(len(before)), np.array(raw_test_auc)[sorting], label = \"Raw (\" + str(np.round(np.mean(raw_test_auc), 2)) + \")\")\n",
    "plt.scatter(np.arange(len(before)), np.array(before)[sorting], label = \"Before (\" + str(np.round(np.mean(before), 2)) + \")\")\n",
    "plt.scatter(np.arange(len(before)), np.array(after)[sorting], label = \"After (\" + str(np.round(np.mean(after), 2)) + \")\")\n",
    "plt.ylim([-0.1, 1.1])\n",
    "plt.legend(fontsize = 20)\n",
    "\n",
    "plt.savefig(\"Images/Histories/(MANUAL)SpectrumEffectImprovement_aupr.png\", format=\"png\", transparent = True,\n",
    "                    dpi = 1000,\n",
    "                    bbox_inches='tight',\n",
    "                    pad_inches=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce988051-ccb2-4a93-bb4c-e6612fd1ec5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "before = np.load(\"Results/(MANUAL)FinalLGMAccuracies(Before).npy\")\n",
    "after = np.load(\"Results/(MANUAL)FinalLGMAccuracies.npy\")\n",
    "raw = np.load(\"Results/(RAW)FinalLGMAccuracies(Before).npy\")\n",
    "plt.rcParams.update({'font.size': 30})\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "\n",
    "#sorting = np.argsort(after)\n",
    "\n",
    "plt.figure(figsize = (10, 5))\n",
    "#plt.plot(before[sorting], alpha = 0.3)\n",
    "#plt.plot(after[sorting], alpha = 0.3)\n",
    "plt.scatter(np.arange(len(before)), np.array(raw)[sorting], label = \"Raw (\" + str(np.round(np.mean(before), 2)) + \")\")\n",
    "plt.scatter(np.arange(len(before)), np.array(before)[sorting], label = \"Before (\" + str(np.round(np.mean(before), 2)) + \")\")\n",
    "plt.scatter(np.arange(len(before)), np.array(after)[sorting], label = \"After (\" + str(np.round(np.mean(after), 2)) + \")\")\n",
    "plt.ylim([-0.1, 1.1])\n",
    "plt.legend(fontsize = 20)\n",
    "\n",
    "plt.savefig(\"Images/Histories/(MANUAL)LGMAccuracyChanges.png\", format=\"png\", transparent = True,\n",
    "                    dpi = 1000,\n",
    "                    bbox_inches='tight',\n",
    "                    pad_inches=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d646ae24-fd2f-4ad2-875c-2f099adfb99d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
