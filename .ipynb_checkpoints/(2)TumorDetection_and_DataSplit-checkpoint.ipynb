{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7807abd0-61cd-45fb-856d-6e212647fdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Scripts.essentials import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97adc53e-f375-4e48-acd7-963b11536a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_data = np.load(\"Data/FlatData.npy\")\n",
    "flat_data_RADAR = np.load(\"Data/FlatDataRADAR.npy\")\n",
    "flat_data_MANUAL = np.load(\"Data/FlatDataMANUAL.npy\")\n",
    "\n",
    "patient_id = np.load(\"Data/patient_id.npy\")\n",
    "lgm_labels = np.load(\"Data/lgm_labels.npy\")\n",
    "pca_labels = np.load(\"Data/pca_labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07e7364-11c6-41a9-ad85-82dee2e274c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Display the distribution of the different datasets\n",
    "plt.rcParams.update({'font.size': 40})\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "\n",
    "min_ = np.min(normalize(flat_data_RADAR), axis = 0)\n",
    "max_ = np.max(normalize(flat_data_RADAR), axis = 0)\n",
    "sd = np.std(normalize(flat_data_RADAR), axis = 0)\n",
    "mean = np.mean(normalize(flat_data_RADAR), axis = 0)\n",
    "\n",
    "plt.figure(figsize = (7, 5))\n",
    "plt.fill_between(np.arange(1738), min_, max_, alpha = 0.4)\n",
    "plt.fill_between(np.arange(1738), mean - sd, mean + sd, alpha = 0.7, color = \"Red\")\n",
    "plt.plot(mean, linestyle = \"--\", color = \"Black\")\n",
    "plt.title(\"RADAR\")\n",
    "plt.savefig(\"Images/Histories/RADARDistr.png\", format=\"png\", transparent = True,\n",
    "                    dpi = 1000,\n",
    "                    bbox_inches='tight',\n",
    "                    pad_inches=0.5)\n",
    "plt.show()\n",
    "\n",
    "min_ = np.min(flat_data, axis = 0)\n",
    "max_ = np.max(flat_data, axis = 0)\n",
    "sd = np.std(flat_data, axis = 0)\n",
    "mean = np.mean(flat_data, axis = 0)\n",
    "\n",
    "plt.figure(figsize = (7, 5))\n",
    "plt.fill_between(np.arange(1738), min_, max_, alpha = 0.4)\n",
    "plt.fill_between(np.arange(1738), mean - sd, mean + sd, alpha = 0.7, color = \"Red\")\n",
    "plt.plot(mean, linestyle = \"--\", color = \"Black\")\n",
    "plt.title(\"Raw\")\n",
    "plt.savefig(\"Images/Histories/RawDistr.png\", format=\"png\", transparent = True,\n",
    "                    dpi = 1000,\n",
    "                    bbox_inches='tight',\n",
    "                    pad_inches=0.5)\n",
    "plt.show()\n",
    "\n",
    "min_ = np.min(flat_data_MANUAL, axis = 0)\n",
    "max_ = np.max(flat_data_MANUAL, axis = 0)\n",
    "sd = np.std(flat_data_MANUAL, axis = 0)\n",
    "mean = np.mean(flat_data_MANUAL, axis = 0)\n",
    "\n",
    "plt.figure(figsize = (7, 5))\n",
    "plt.fill_between(np.arange(1738), min_, max_, alpha = 0.4)\n",
    "plt.fill_between(np.arange(1738), mean - sd, mean + sd, alpha = 0.7, color = \"Red\")\n",
    "plt.plot(mean, linestyle = \"--\", color = \"Black\")\n",
    "plt.title(\"Manually Curated\")\n",
    "plt.savefig(\"Images/Histories/MANUALDistr.png\", format=\"png\", transparent = True,\n",
    "                    dpi = 1000,\n",
    "                    bbox_inches='tight',\n",
    "                    pad_inches=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd57b19f-304b-4cae-b977-44cf8ae00221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the 5000 first spectra, are there outliers? (Yes!)\n",
    "plt.plot(normalize(flat_data_RADAR[0:5000]).T)\n",
    "plt.show()\n",
    "plt.plot(flat_data[0:5000].T)\n",
    "plt.show()\n",
    "plt.plot(flat_data_MANUAL[0:5000].T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ae2e45-35a6-4bc8-9bcc-08138bbf3196",
   "metadata": {},
   "source": [
    "# Persisting non-tumor spectra\n",
    "Remove them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113735bb-5099-4758-bacc-b1832f0ad623",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = np.load(\"Data/FlatDataMANUAL.npy\")\n",
    "\n",
    "for qs in [[0.005, 0.995]]:\n",
    "    # Use quantiles to detect outliers\n",
    "    min_ = np.quantile(norm, q = qs[0], axis = 0)\n",
    "    max_ = np.quantile(norm, q = qs[1], axis = 0)\n",
    "\n",
    "    # Get the indices of spectra which are outside the quantiles\n",
    "    np.bitwise_and( norm[:, 0] < min_[0], norm[:, 0] > max_[0]).shape\n",
    "\n",
    "    # Identify these\n",
    "    non_outliers = np.array([np.bitwise_and(norm[:, i] >= min_[i], norm[:, i] <= max_[i]) for i in range(1738)])\n",
    "    outliers = np.array([np.bitwise_or(norm[:, i] < min_[i], norm[:, i] > max_[i]) for i in range(1738)])\n",
    "\n",
    "    # Get their indices\n",
    "    non_out_ix = np.bitwise_and.reduce(non_outliers, axis = 0)\n",
    "    out_ix = np.bitwise_or.reduce(outliers, axis = 0)\n",
    "\n",
    "\n",
    "    print(\"Tumor spectra found:\", norm[non_out_ix].shape)\n",
    "    print(\"Non-Tumor spectra found:\", norm[out_ix].shape)\n",
    "\n",
    "\n",
    "    # Check the outliers\n",
    "    min_ = np.min(norm[out_ix], axis = 0)\n",
    "    max_ = np.max(norm[out_ix], axis = 0)\n",
    "    sd = np.std(norm[out_ix], axis = 0)\n",
    "    mean = np.mean(norm[out_ix], axis = 0)\n",
    "    plt.fill_between(np.arange(1738), min_, max_, alpha = 0.4)\n",
    "    plt.fill_between(np.arange(1738), mean - sd, mean + sd, alpha = 0.7, color = \"Red\")\n",
    "    plt.plot(mean, linestyle = \"--\", color = \"Black\")\n",
    "    plt.title(\"Non-tumor\")\n",
    "    plt.savefig(\"Images/Histories/MANUALOutliers.png\", format=\"png\", transparent = True,\n",
    "                    dpi = 1000,\n",
    "                    bbox_inches='tight',\n",
    "                    pad_inches=0.5)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    # Check non-outliers\n",
    "    min_ = np.min(norm[non_out_ix], axis = 0)\n",
    "    max_ = np.max(norm[non_out_ix], axis = 0)\n",
    "    sd = np.std(norm[non_out_ix], axis = 0)\n",
    "    mean = np.mean(norm[non_out_ix], axis = 0)\n",
    "    plt.fill_between(np.arange(1738), min_, max_, alpha = 0.4)\n",
    "    plt.fill_between(np.arange(1738), mean - sd, mean + sd, alpha = 0.7, color = \"Red\")\n",
    "    plt.plot(mean, linestyle = \"--\", color = \"Black\")\n",
    "    plt.title(\"Tumor\")\n",
    "    plt.savefig(\"Images/Histories/MANUALTumor.png\", format=\"png\", transparent = True,\n",
    "                    dpi = 1000,\n",
    "                    bbox_inches='tight',\n",
    "                    pad_inches=0.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a49063-572a-4a88-8f4e-59b604151a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Show the distribution of the different LGm classes\n",
    "colors = [\"Green\", \"Blue\", \"orange\", \"cyan\", \"magenta\", \"brown\"]\n",
    "plt.figure(figsize = (10, 7))\n",
    "for lgm in np.unique(lgm_labels).astype(int)-1:\n",
    "    d = norm[non_out_ix]\n",
    "    d = d[lgm_labels[non_out_ix].astype(int) == lgm+1]\n",
    "\n",
    "    min_ = np.min(d, axis = 0)\n",
    "    max_ = np.max(d, axis = 0)\n",
    "    sd = np.std(d, axis = 0)\n",
    "    mean = np.mean(d, axis = 0)\n",
    "\n",
    "    plt.fill_between(np.arange(1738), mean - sd, mean + sd, alpha = 0.7, color = colors[lgm])\n",
    "    plt.plot(mean, linestyle = \"--\", color = \"black\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0c1488-93ac-4903-aad3-e5df88ae0b7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Store pca plots before outlier removal to see their influence on the surfaces\n",
    "pca = PCA(n_components = 3)\n",
    "mean_ = np.expand_dims(np.mean(norm, axis = 0), 0)\n",
    "std_ = np.expand_dims(np.std(norm, axis = 0), 0)\n",
    "\n",
    "# Since PCA works by comparing variances per frequency, we standardize the frequencies of the entire dataset\n",
    "std_data = (norm - mean_)/ (std_ + 0.00001)\n",
    "\n",
    "# Train the pca model for the entire dataset\n",
    "pca.fit(np.squeeze(std_data))\n",
    "\n",
    "data_path = \"Data/RawData/\"\n",
    "\n",
    "for lgm in os.listdir(data_path):\n",
    "    \n",
    "    if lgm in [\"LGm-1\", \"LGm-2\", \"LGm-3\", \"LGm-4\",\"LGm-5\", \"LGm-6\"]:\n",
    "        sample_path = data_path + lgm + \"/\"\n",
    "        for sample in os.listdir(sample_path):\n",
    "            sample_shape = np.load(sample_path+sample).shape\n",
    "                \n",
    "            print(sample)\n",
    "            sample_spectra = norm[sample == patient_id]\n",
    "            \n",
    "            image = np.zeros((len(sample_spectra), 3))\n",
    "\n",
    "            std_data = (sample_spectra - mean_)/ (std_ + 0.00001)\n",
    "            points = pca.transform(std_data)\n",
    "            _min = np.expand_dims(np.min(points, axis = 0), 0)\n",
    "            _max = np.expand_dims(np.max(points, axis = 0), 0)\n",
    "            points = ((points - _min) / (_max - _min)) * 255\n",
    "            \n",
    "    \n",
    "            image = points\n",
    "            image = image.astype(int)\n",
    "            image = image.reshape((sample_shape[0], sample_shape[1], 3))\n",
    "            np.save(\"Data/PCA_maps/\" + sample +\"_\" +str(lgm)+\".npy\", image)\n",
    "            plt.imshow(image)\n",
    "            plt.savefig(\"Images/PCA_before_outlier_removal/\"+sample +\".png\")\n",
    "            plt.show()\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56de0b48-94d4-4932-b667-c90bd7189dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 3)\n",
    "mean_ = np.expand_dims(np.mean(norm[non_out_ix], axis = 0), 0)\n",
    "std_ = np.expand_dims(np.std(norm[non_out_ix], axis = 0), 0)\n",
    "\n",
    "# Since PCA works by comparing variances per frequency, we standardize the frequencies of the entire dataset\n",
    "std_data = (norm[non_out_ix] - mean_)/ (std_ + 0.00001)\n",
    "\n",
    "# Train the pca model for the entire dataset\n",
    "pca.fit(np.squeeze(std_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972269f8-9a3f-4629-a793-6d53ad2fc333",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_path = \"Data/RawData/\"\n",
    "\n",
    "for lgm in os.listdir(data_path):\n",
    "    \n",
    "    if lgm in [\"LGm-1\", \"LGm-2\", \"LGm-3\", \"LGm-4\",\"LGm-5\", \"LGm-6\"]:\n",
    "        sample_path = data_path + lgm + \"/\"\n",
    "        for sample in os.listdir(sample_path):\n",
    "            sample_shape = np.load(sample_path+sample).shape\n",
    "                \n",
    "            print(sample)\n",
    "            \n",
    "            tumor_ix = non_out_ix[sample == patient_id]\n",
    "            sample_spectra = norm[sample == patient_id]\n",
    "            \n",
    "            image = np.zeros((len(sample_spectra), 3))\n",
    "            \n",
    "            sample_spectra = sample_spectra[tumor_ix]\n",
    "            \n",
    "            std_data = (sample_spectra - mean_)/ (std_ + 0.00001)\n",
    "            points = pca.transform(std_data)\n",
    "            _min = np.expand_dims(np.min(points, axis = 0), 0)\n",
    "            _max = np.expand_dims(np.max(points, axis = 0), 0)\n",
    "            points = ((points - _min) / (_max - _min)) * 255\n",
    "            \n",
    "    \n",
    "            image[tumor_ix] = points\n",
    "            image = image.astype(int)\n",
    "            image = image.reshape((sample_shape[0], sample_shape[1], 3))\n",
    "            np.save(\"Data/PCA_maps/\" + sample +\"_\" +str(lgm)+\".npy\", image)\n",
    "            plt.imshow(image)\n",
    "            plt.savefig(\"Images/TumorMaps/\"+sample +\"_pca.png\")\n",
    "            plt.show()\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbaa33be-ff75-464d-b5b6-87399ff3ce5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the outliers from the datasets\n",
    "flat_data_RADAR = flat_data_RADAR[non_out_ix]\n",
    "flat_data = flat_data[non_out_ix]\n",
    "flat_data_MANUAL = flat_data_MANUAL[non_out_ix]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfabbe90-cb8b-4c47-aac6-a528d55a75ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Display the distribution of the different datasets\n",
    "plt.rcParams.update({'font.size': 40})\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "\n",
    "min_ = np.min(normalize(flat_data_RADAR), axis = 0)\n",
    "max_ = np.max(normalize(flat_data_RADAR), axis = 0)\n",
    "sd = np.std(normalize(flat_data_RADAR), axis = 0)\n",
    "mean = np.mean(normalize(flat_data_RADAR), axis = 0)\n",
    "\n",
    "plt.figure(figsize = (7, 5))\n",
    "plt.fill_between(np.arange(1738), min_, max_, alpha = 0.4)\n",
    "plt.fill_between(np.arange(1738), mean - sd, mean + sd, alpha = 0.7, color = \"Red\")\n",
    "plt.plot(mean, linestyle = \"--\", color = \"Black\")\n",
    "plt.title(\"RADAR\")\n",
    "plt.savefig(\"Images/Histories/RADARDistrPrep.png\", format=\"png\", transparent = True,\n",
    "                    dpi = 1000,\n",
    "                    bbox_inches='tight',\n",
    "                    pad_inches=0.5)\n",
    "plt.show()\n",
    "\n",
    "min_ = np.min(flat_data, axis = 0)\n",
    "max_ = np.max(flat_data, axis = 0)\n",
    "sd = np.std(flat_data, axis = 0)\n",
    "mean = np.mean(flat_data, axis = 0)\n",
    "\n",
    "plt.figure(figsize = (7, 5))\n",
    "plt.fill_between(np.arange(1738), min_, max_, alpha = 0.4)\n",
    "plt.fill_between(np.arange(1738), mean - sd, mean + sd, alpha = 0.7, color = \"Red\")\n",
    "plt.plot(mean, linestyle = \"--\", color = \"Black\")\n",
    "plt.title(\"Raw\")\n",
    "plt.savefig(\"Images/Histories/RawDistrPrep.png\", format=\"png\", transparent = True,\n",
    "                    dpi = 1000,\n",
    "                    bbox_inches='tight',\n",
    "                    pad_inches=0.5)\n",
    "plt.show()\n",
    "\n",
    "min_ = np.min(flat_data_MANUAL, axis = 0)\n",
    "max_ = np.max(flat_data_MANUAL, axis = 0)\n",
    "sd = np.std(flat_data_MANUAL, axis = 0)\n",
    "mean = np.mean(flat_data_MANUAL, axis = 0)\n",
    "\n",
    "plt.figure(figsize = (7, 5))\n",
    "plt.fill_between(np.arange(1738), min_, max_, alpha = 0.4)\n",
    "plt.fill_between(np.arange(1738), mean - sd, mean + sd, alpha = 0.7, color = \"Red\")\n",
    "plt.plot(mean, linestyle = \"--\", color = \"Black\")\n",
    "plt.title(\"Manually Curated\")\n",
    "plt.savefig(\"Images/Histories/MANUALDistrPrep.png\", format=\"png\", transparent = True,\n",
    "                    dpi = 1000,\n",
    "                    bbox_inches='tight',\n",
    "                    pad_inches=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35ab903-e0d8-4d7f-b3b6-7193b0e91f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the labels corresponding with outliers\n",
    "patient_id = patient_id[non_out_ix]\n",
    "lgm_labels = lgm_labels[non_out_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfe1f4a-64a5-45e7-8b37-41a6a2bd3bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a random train, test, validation split on each sample for each of the different preprocessing methods\n",
    "\n",
    "spectrum_len = len(flat_data[0])\n",
    "print(spectrum_len)\n",
    "\n",
    "train_x, test_x, val_x = np.empty((0, spectrum_len)), np.empty((0, spectrum_len)), np.empty((0, spectrum_len))\n",
    "train_x_RADAR, test_x_RADAR, val_x_RADAR = np.empty((0, spectrum_len)), np.empty((0, spectrum_len)), np.empty((0, spectrum_len))\n",
    "train_x_MANUAL, test_x_MANUAL, val_x_MANUAL = np.empty((0, spectrum_len)), np.empty((0, spectrum_len)), np.empty((0, spectrum_len))\n",
    "\n",
    "train_y, test_y, val_y = np.empty((0)), np.empty((0)), np.empty((0))\n",
    "train_pca, test_pca, val_pca = np.empty((0)), np.empty((0)), np.empty((0))\n",
    "train_lgm, test_lgm, val_lgm = np.empty((0)), np.empty((0)), np.empty((0))\n",
    "\n",
    "unique_ids = np.arange(len(np.unique(patient_id)))\n",
    "num_ids = len(unique_ids)\n",
    "\n",
    "unique_pca = np.unique(pca_labels)\n",
    "num_pca = len(unique_pca)\n",
    "\n",
    "unique_lgm = np.unique(lgm_labels)\n",
    "num_lgm = len(unique_lgm)\n",
    "\n",
    "# Check the minimum possible length (if we take a uniform amout from each sample, otherwise can be ignored)\n",
    "min_spectra = np.inf\n",
    "for l in np.unique(patient_id):\n",
    "    l = len(flat_data[patient_id == l])\n",
    "\n",
    "    if l < min_spectra:\n",
    "        min_spectra = l\n",
    "        \n",
    "print(\"smallest sample size:\", min_spectra)\n",
    "\n",
    "\n",
    "for num_label, label in enumerate(np.unique(patient_id)):\n",
    "    print(label, num_label)\n",
    "    sample = np.copy(np.squeeze(flat_data[patient_id == label]))\n",
    "    sample_RADAR = np.copy(np.squeeze(flat_data_RADAR[patient_id == label]))\n",
    "    sample_MANUAL = np.copy(np.squeeze(flat_data_MANUAL[patient_id == label]))\n",
    "\n",
    "    lgm_labs = np.copy(np.squeeze(lgm_labels[patient_id == label]))\n",
    "    \n",
    "    num_spectra = len(sample)\n",
    "\n",
    "    \n",
    "    ix = np.arange(num_spectra)\n",
    "    train_split = int(num_spectra * 0.8) # 80% of the sample spectra allocated to training\n",
    "    test_split = train_split + int((num_spectra - train_split) * 0.5) # The remaining spectra are split 50/50 between validation and test\n",
    "    val_split = num_spectra\n",
    "\n",
    "    # Shuffle the data\n",
    "    np.random.seed(0)\n",
    "    np.random.shuffle(ix)\n",
    "    sample = np.squeeze(sample[ix])\n",
    "    sample_RADAR = np.squeeze(sample_RADAR[ix])\n",
    "    sample_MANUAL = np.squeeze(sample_MANUAL[ix])\n",
    "    \n",
    "    # Assign the datapoints to the split\n",
    "    print(train_x.shape, sample.shape, num_spectra)\n",
    "    train_x = np.concatenate((train_x, sample[: train_split]), axis = 0)\n",
    "    test_x = np.concatenate((test_x, sample[train_split: test_split]), axis = 0)\n",
    "    val_x = np.concatenate((val_x, sample[test_split: val_split]), axis = 0)\n",
    "\n",
    "    train_x_RADAR = np.concatenate((train_x_RADAR, sample_RADAR[: train_split]), axis = 0)\n",
    "    test_x_RADAR = np.concatenate((test_x_RADAR, sample_RADAR[train_split: test_split]), axis = 0)\n",
    "    val_x_RADAR = np.concatenate((val_x_RADAR, sample_RADAR[test_split: val_split]), axis = 0)\n",
    "\n",
    "    train_x_MANUAL = np.concatenate((train_x_MANUAL, sample_MANUAL[: train_split]), axis = 0)\n",
    "    test_x_MANUAL = np.concatenate((test_x_MANUAL, sample_MANUAL[train_split: test_split]), axis = 0)\n",
    "    val_x_MANUAL = np.concatenate((val_x_MANUAL, sample_MANUAL[test_split: val_split]), axis = 0)\n",
    "\n",
    "    # Provide labels for the different sets, for ID classificaton\n",
    "    train_y = np.concatenate((train_y, np.ones(train_split) * num_label))\n",
    "    test_y = np.concatenate((test_y, np.ones(test_split - train_split) * num_label))\n",
    "    val_y = np.concatenate((val_y, np.ones(val_split - test_split) * num_label))\n",
    "\n",
    "    # Methylation labels\n",
    "    train_lgm = np.concatenate((train_lgm, lgm_labs[: train_split]))\n",
    "    test_lgm = np.concatenate((test_lgm, lgm_labs[train_split: test_split]))\n",
    "    val_lgm = np.concatenate((val_lgm, lgm_labs[test_split: val_split]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ee152e-21ee-4652-9b7d-4a5ba8de392c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle after training set to obfuscate sample of origin\n",
    "indices = np.arange(len(train_x))\n",
    "np.random.seed(0)\n",
    "np.random.shuffle(indices)\n",
    "train_x = train_x[indices]\n",
    "train_x_RADAR = train_x_RADAR[indices]\n",
    "train_x_MANUAL = train_x_MANUAL[indices]\n",
    "\n",
    "# Remember to shuffle the labels as well\n",
    "train_y = train_y[indices]\n",
    "train_lgm = train_lgm[indices]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509a32be-3a4b-414a-a46e-00d1e31779c1",
   "metadata": {},
   "source": [
    "# Based on the above enumeration of the samples, the ones which share the prefix patient id are listed here for ease of access\n",
    "\n",
    "\n",
    "HF-1002: [0, 1]\n",
    "\n",
    "HF-2102: [12, 13, 14]\n",
    "\n",
    "HF-2104: [15, 16, 17]\n",
    "\n",
    "HF-2493: [22, 23]\n",
    "\n",
    "HF-2619: [30, 31]\n",
    "\n",
    "HF-2849: [36, 37, 38, 39]\n",
    "\n",
    "HF-682:  [50, 51]\n",
    "\n",
    "HF-894:  [53, 54]\n",
    "\n",
    "HF-988:  [57, 58]\n",
    "\n",
    "With this the total number of unique sample ids would be 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fa75c2-3c32-44f6-9426-a9922b064f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.shape, val_x.shape, test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8484512-105b-4999-aca8-175cd96094b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot-encode ids\n",
    "eye = np.eye(len(np.unique(patient_id)))\n",
    "train_y = eye[train_y.astype(int)]\n",
    "test_y = eye[test_y.astype(int)]\n",
    "val_y = eye[val_y.astype(int)]\n",
    "\n",
    "# One-hot-encode lgm \n",
    "eye = np.eye(len(np.unique(lgm_labels.astype(int))))\n",
    "train_lgm = eye[train_lgm.astype(int)-1]\n",
    "test_lgm = eye[test_lgm.astype(int)-1]\n",
    "val_lgm = eye[val_lgm.astype(int)-1]\n",
    "\n",
    "# One-hot-encode pca \n",
    "eye = np.eye(len(np.unique(pca_labels.astype(int))))\n",
    "train_pca = eye[train_pca.astype(int)-1]\n",
    "test_pca = eye[test_pca.astype(int)-1]\n",
    "val_pca = eye[val_pca.astype(int)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01dfe023-3ee8-428e-bf62-c0f3844271c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the 5000 first spectra in each dataset again, outliers appear to be removed\n",
    "\n",
    "plt.figure(figsize = (20, 5))\n",
    "plt.plot(train_x_RADAR[:5000].T)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize = (20, 5))\n",
    "plt.plot(train_x[:5000].T)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize = (20, 5))\n",
    "plt.plot(train_x_MANUAL[:5000].T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c20acad-af83-445b-a21f-478a8ce884c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "p = \"Data/\"\n",
    "\n",
    "np.save(p + \"train_x.npy\", train_x)\n",
    "np.save(p + \"train_x_RADAR.npy\", normalize(train_x_RADAR))\n",
    "np.save(p + \"train_x_MANUAL.npy\", normalize(train_x_MANUAL))\n",
    "\n",
    "np.save(p + \"test_x.npy\", test_x)\n",
    "np.save(p + \"test_x_RADAR.npy\", normalize(test_x_RADAR))\n",
    "np.save(p + \"test_x_MANUAL.npy\", normalize(test_x_MANUAL))\n",
    "\n",
    "np.save(p + \"val_x.npy\", val_x)\n",
    "np.save(p + \"val_x_RADAR.npy\", normalize(val_x_RADAR))\n",
    "np.save(p + \"val_x_MANUAL.npy\", normalize(val_x_MANUAL))\n",
    "\n",
    "np.save(p + \"train_y.npy\", train_y)\n",
    "np.save(p + \"test_y.npy\", test_y)\n",
    "np.save(p + \"val_y.npy\", val_y)\n",
    "\n",
    "np.save(p + \"train_lgm.npy\", train_lgm)\n",
    "np.save(p + \"test_lgm.npy\", test_lgm)\n",
    "np.save(p + \"val_lgm.npy\", val_lgm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bb8bf7-26d9-4871-b102-e69cb61a027c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary with the simplified label enumerations\n",
    "# Combine sample IDs according to patient labels\n",
    "unique_labels = np.unique([name.split(\"_\")[0] for name in list(np.unique(patient_id))])\n",
    "print(len(unique_labels))\n",
    "label_dict = {}\n",
    "for en, n in enumerate(unique_labels):\n",
    "    label_dict[n] = en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce73e90-e1ed-4841-8468-7f8a575f2135",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = \"Data/\"\n",
    "\n",
    "train_y = np.load(p + \"train_y.npy\")\n",
    "test_y = np.load(p + \"test_y.npy\")\n",
    "val_y = np.load(p + \"val_y.npy\")\n",
    "\n",
    "for y, name in zip([train_y, val_y, test_y], [\"train_y_46.npy\", \"val_y_46.npy\", \"test_y_46.npy\"]):\n",
    "    \n",
    "    train_y_copy = np.argmax(y, axis = 1)\n",
    "    \n",
    "    for en, full_id in enumerate(np.unique(patient_id)):\n",
    "\n",
    "        simple_label = full_id.split(\"_\")[0]\n",
    "        train_y_copy[train_y_copy == en] = label_dict[simple_label]\n",
    "\n",
    "    eye = np.eye(len(np.unique(train_y_copy)))\n",
    "    train_y_copy = eye[train_y_copy]\n",
    "    np.save(\"Data/\"+name, train_y_copy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
